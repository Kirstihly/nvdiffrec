{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d8e5377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, json, os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6369b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, eps = 1.0e-8, fallback = None):\n",
    "    x = np.asarray(x, dtype=np.float64)\n",
    "    norm_x = np.linalg.norm(x)\n",
    "    if norm_x < eps:\n",
    "        if fallback is None:\n",
    "            raise ValueError(\"Expected non-zero vector.\")\n",
    "        else:\n",
    "            return np.asarray(fallback, dtype=np.float64)\n",
    "    return x / norm_x\n",
    "\n",
    "def ensure_3d_vector(x):\n",
    "    x = np.asarray(x, dtype=np.float64)\n",
    "    if x.shape != (3,):\n",
    "        raise ValueError(f\"Expected shape=(3,), got {x.shape}\")\n",
    "    return x\n",
    "\n",
    "def convert_str_direction_to_vector(direction):\n",
    "    return {\n",
    "        \"X\": np.array([1., 0., 0.], dtype=np.float64),\n",
    "        \"Y\": np.array([0., 1., 0.], dtype=np.float64),\n",
    "        \"Z\": np.array([0., 0., 1.], dtype=np.float64),\n",
    "        \"-X\": np.array([-1., 0., 0.], dtype=np.float64),\n",
    "        \"-Y\": np.array([0., -1., 0.], dtype=np.float64),\n",
    "        \"-Z\": np.array([0., 0., -1.], dtype=np.float64),\n",
    "    }[direction.upper()]\n",
    "\n",
    "def look_at_quat(position, target, up = \"Y\", front = \"-Z\"):\n",
    "    # convert directions to vectors if needed\n",
    "    world_up = convert_str_direction_to_vector(\"Z\")\n",
    "    world_right = convert_str_direction_to_vector(\"X\")\n",
    "    if isinstance(up, str):\n",
    "        up = convert_str_direction_to_vector(up)\n",
    "    if isinstance(front, str):\n",
    "        front = convert_str_direction_to_vector(front)\n",
    "\n",
    "    up = normalize(ensure_3d_vector(up))\n",
    "    front = normalize(ensure_3d_vector(front))\n",
    "    right = np.cross(up, front)\n",
    "\n",
    "    target = ensure_3d_vector(target)\n",
    "    position = ensure_3d_vector(position)\n",
    "\n",
    "    # construct the desired coordinate basis front, right, up\n",
    "    look_at_front = normalize(target - position)\n",
    "    look_at_right = normalize(np.cross(world_up, look_at_front), fallback=world_right)\n",
    "    look_at_up = normalize(np.cross(look_at_front, look_at_right), fallback=world_up)\n",
    "\n",
    "    rotation_matrix1 = np.stack([look_at_right, look_at_up, look_at_front])\n",
    "    rotation_matrix2 = np.stack([right, up, front])\n",
    "    return rotation_matrix1.T @ rotation_matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc32170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJson(path):\n",
    "    f = open(path)\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "    return data\n",
    "\n",
    "# (q0,q1,q2,q3) = (W, X, Y, Z)\n",
    "def quaternion_to_rotation_matrix(Q):\n",
    "    \"\"\"\n",
    "    Covert a quaternion into a full three-dimensional rotation matrix.\n",
    " \n",
    "    Input\n",
    "    :param Q: A 4 element array representing the quaternion (q0,q1,q2,q3) \n",
    " \n",
    "    Output\n",
    "    :return: A 3x3 element matrix representing the full 3D rotation matrix. \n",
    "             This rotation matrix converts a point in the local reference \n",
    "             frame to a point in the global reference frame.\n",
    "    \"\"\"\n",
    "    # Extract the values from Q\n",
    "    q0 = Q[0]\n",
    "    q1 = Q[1]\n",
    "    q2 = Q[2]\n",
    "    q3 = Q[3]\n",
    "     \n",
    "    # First row of the rotation matrix\n",
    "    r00 = 2 * (q0 * q0 + q1 * q1) - 1\n",
    "    r01 = 2 * (q1 * q2 - q0 * q3)\n",
    "    r02 = 2 * (q1 * q3 + q0 * q2)\n",
    "     \n",
    "    # Second row of the rotation matrix\n",
    "    r10 = 2 * (q1 * q2 + q0 * q3)\n",
    "    r11 = 2 * (q0 * q0 + q2 * q2) - 1\n",
    "    r12 = 2 * (q2 * q3 - q0 * q1)\n",
    "     \n",
    "    # Third row of the rotation matrix\n",
    "    r20 = 2 * (q1 * q3 - q0 * q2)\n",
    "    r21 = 2 * (q2 * q3 + q0 * q1)\n",
    "    r22 = 2 * (q0 * q0 + q3 * q3) - 1\n",
    "     \n",
    "    # 3x3 rotation matrix\n",
    "    rot_matrix = np.array([[r00, r01, r02],\n",
    "                           [r10, r11, r12],\n",
    "                           [r20, r21, r22]])\n",
    "                            \n",
    "    return rot_matrix\n",
    "\n",
    "def convertTransformMatrix(target, translation, quaternion):\n",
    "    \n",
    "    # Find world-to-cam pose\n",
    "    transform = np.identity(4)\n",
    "    # T: (X, Y, Z)\n",
    "    transform[0:3, 3] = np.array(translation)\n",
    "    # Q: (W, X, Y, Z)\n",
    "    transform[0:3, 0:3] = quaternion_to_rotation_matrix(quaternion)\n",
    "    \n",
    "    # Find cam-to-world pose\n",
    "    # cam:   up -> Y, front -> -Z, right -> -X\n",
    "    # world: up -> Z, front -> -Y, right -> X\n",
    "    look_at_transform = np.identity(4)\n",
    "    position = transform @ target\n",
    "    \n",
    "    look_at_transform[0:3, 0:3] = look_at_quat(position[:3], target[:3], up = \"Y\", front = \"-Z\")\n",
    "    look_at_transform[0:3, 3] = np.array([-translation[0], -translation[2], -translation[1]])\n",
    "\n",
    "    return look_at_transform\n",
    "        \n",
    "#     transform = np.identity(4)\n",
    "#     transform[0:3, 3] = np.array([-translation[0], -translation[2], translation[1]])\n",
    "#     transform[0:3, 0:3] = quaternion_to_rotation_matrix([quaternion[0], -quaternion[1], -quaternion[3], quaternion[2]])\n",
    "    \n",
    "#     return transform\n",
    "\n",
    "#     c2w_mats = np.linalg.inv(w2c_mats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ec73326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse 49195 complex brdf objects\n",
    "brdf_paths = glob.glob('/home/leyinghu/Documents/data/complex_brdf/specular/24569/metadata.json')\n",
    "brdf_paths.sort()\n",
    "assert len(brdf_paths) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c54874b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for brdf_path in brdf_paths:\n",
    "    \n",
    "    brdf_dir = os.path.dirname(brdf_path)\n",
    "    brdf_data = readJson(brdf_path)\n",
    "    brdf_images = glob.glob(os.path.join(brdf_dir, 'rgba_*.png'))\n",
    "    assert brdf_data['metadata']['num_frames'] == len(brdf_images)\n",
    "    \n",
    "    # Stores a numpy array of size Nx17\n",
    "    # 17: 3x5 pose matrix and 2 depth values (2 depth values never used)\n",
    "    # 3x5: 3x4 camera-to-world affine transform and 3x1 [height, width, focal]\n",
    "    poses = np.zeros((len(brdf_images), 17))\n",
    "\n",
    "    translations = brdf_data['camera']['positions']\n",
    "    quaternions = brdf_data['camera']['quaternions']\n",
    "    if 'width' in brdf_data['metadata']:\n",
    "        focal = brdf_data['metadata']['width'] * brdf_data['camera']['K'][0][0]\n",
    "        width = brdf_data['metadata']['width']\n",
    "        height = brdf_data['metadata']['height']\n",
    "    elif 'resolution' in brdf_data['metadata']:\n",
    "        focal = brdf_data['metadata']['resolution'][0] * brdf_data['camera']['K'][0][0]\n",
    "        width = brdf_data['metadata']['resolution'][0]\n",
    "        height = brdf_data['metadata']['resolution'][1]\n",
    "    bboxes_3d = brdf_data['instances'][0]['bboxes_3d'][0]\n",
    "    target = np.ones(shape=[4], dtype=np.float64)\n",
    "    target[:-1] = np.average(np.array(bboxes_3d), axis = 0)\n",
    "    \n",
    "    for i in range(len(translations)):\n",
    "        \n",
    "        assert bboxes_3d == brdf_data['instances'][0]['bboxes_3d'][i]\n",
    "        \n",
    "        transform = np.zeros((3,5))\n",
    "        transform[:, :-1] = convertTransformMatrix(target, translations[i], quaternions[i])[:-1, :]\n",
    "        transform[0, 4] = height\n",
    "        transform[1, 4] = width\n",
    "        transform[2, 4] = focal\n",
    "        \n",
    "        poses[i, :-2] = transform.reshape((1, 15))\n",
    "        \n",
    "    pose_path = os.path.join(brdf_dir, 'poses_bounds.npy')\n",
    "    np.save(pose_path, poses)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e408de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
